version: '3'
### YAML Anchors ###
x-gpu: &gpu
  build:
    args:
      - BASE='nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04'
  runtime: nvidia
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: ["compute", "utility", "graphics"]

####
services:
  wyoming-piper:
    extends:
      file: docker-compose.base.yml
      service: wyoming-piper
    <<: [ *gpu ]
    build:
      args:
        - BASE='nvidia/cuda:11.2.2-cudnn8-runtime-ubuntu20.04'
        - EXTRA_DEPENDENCIES='onnxruntime-gpu'
        - RUN_SCRIPT='run-gpu.sh'
    volumes:
      - ./piper/__main__.py:/usr/local/lib/python3.10/dist-packages/wyoming_piper/__main__.py
      - ./piper/process.py:/usr/local/lib/python3.10/dist-packages/wyoming_piper/process.py

  wyoming-whisper:
    extends:
      file: docker-compose.base.yml
      service: wyoming-whisper
    <<: [ *gpu ]
    command: [ "--model", "tiny-int8", "--language", "en", "--device", "cuda" ]

#  wyoming-whispercpp:
#    extends:
#      file: docker-compose.base.yml
#      service: wyoming-whispercpp
#    <<: [ *gpu ]
#    command: [ "--model", "tiny-int8", "--language", "en", "--device", "cuda" ]

  wyoming-openwakeword:
    extends:
      file: docker-compose.base.yml
      service: wyoming-openwakeword
    <<: [ *gpu ]

#  wyoming-porcupine:
#    extends:
#      file: docker-compose.base.yml
#      service: wyoming-porcupine
#    <<: [ *gpu ]

#  wyoming-snowboy:
#    extends:
#      file: docker-compose.base.yml
#      service: wyoming-snowboy
#    <<: [ *gpu ]

#  wyoming-vosk:
#    extends:
#      file: docker-compose.base.yml
#      service: wyoming-vosk
#    <<: [ *gpu ]

